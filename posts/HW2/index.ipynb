{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"A Web-scraping Spaghetti Western Recommender\"\n",
    "author: \"Ziyan\"\n",
    "date: \"2025-02-09\"\n",
    "categories: [homework]\n",
    "format:\n",
    "  html:\n",
    "    code-overflow: wrap\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to another Python tutorial! Today, we’re building a cool web scraper using `scrapy`.\n",
    "\n",
    "Ever watched a movie and got so hooked on an actor’s performance that you just had to see more of their work? Why not let a web scraper do the searching for you? Let's make it happen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the project set up! First, make sure `scrapy` is installed in your conda environment.\n",
    "\n",
    "Next, open a terminal and run:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "```bash\n",
    "scrapy startproject TMDB_scraper\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will initialize a new scrapy project called \"TMDB_scraper\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s kick things off by creating a new file inside the `spiders` directory, and name it `tmdb_spider.py`.\n",
    "\n",
    "We’re going to pull data from the <a href=\"https://www.themoviedb.org/?language=en-US\">TMDB</a> website for our task.\n",
    "\n",
    "Let's add the following lines to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class TmdbSpider(scrapy.Spider):\n",
    "    name = 'tmdb_spider'\n",
    "    def __init__(self, subdir=\"\", *args, **kwargs):\n",
    "        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have named our spider to be \"tmdb_spider\", and later we will be able to run the completed spider for any movie by giving its subdirectory on TMDB website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Movie Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first challenges in writing a web scraper is navigating a site's structure programmatically.\n",
    "\n",
    "Let's break down our first parsing function, which handles the initial navigation from a movie's main page to its full credits page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def parse(self, response):\n",
    "        \"\"\"Parse movie page and navigate to full credits page.\n",
    "        \tArgs: Response object containing the movie page HTML\n",
    "       \t\tYields: Request object for the full credits page\n",
    "        \"\"\"\n",
    "        cast_link = response.css('.new_button a::attr(href)').get()\n",
    "        yield response.follow(cast_link, callback=self.parse_full_credits)\n",
    "        # or we can do this with hard coding:\n",
    "        # yield response.follow(\"cast\", callback=self.parse_full_credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a CSS selector to locate the \"Full Cast & Crew\" link by targeting an anchor tag within an element with the class `new_button` and extracting its `href` attribute.\n",
    "\n",
    "Instead of constructing the URL manually, we can use Scrapy's built-in `response.follow()` method. It automatically handles relative URLs.\n",
    "\n",
    "Since the TMDB website consistently uses \"/cast\" for every movie's cast and crew page, we can also hardcode the path instead of using a CSS selector.\n",
    "\n",
    "We specify `parse_full_credits` as the callback function, ensuring that once we reach the cast page, that method handles the next stage of the scraping process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Full Cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to our second function, we'll try to extract links to individual actor pages from the full credits page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def parse_full_credits(self, response):\n",
    "        \"\"\"Parse the full credits page and navigate to each actor's page.\n",
    "        \tArgs: Response object containing the full credits page HTML\n",
    "            Yields: Request objects for each actor's page\n",
    "    \t\"\"\"\n",
    "        actor_links = response.css('ol.people.credits:not(.crew) li div.info p a::attr(href)').getall()\n",
    "        for link in actor_links:\n",
    "            yield response.follow(link, callback=self.parse_actor_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `ol.people.credits` targets an ordered list with classes `people` and `credits`.\n",
    "\n",
    "We can use the CSS pseudoclass `:not(.crew)` to exclude elements with class `crew` -- we'll focus only on actors!\n",
    "\n",
    "Then, `li div.info p a` navigates through the HTML to find actor links, extracting the URL from each link just as in the previous function.\n",
    "\n",
    "Finally, we set `parse_actor_page` as the callback for processing each actor's information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Actor Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of our scraping project is extracting structured data. Let's see how our `parse_actor_page` function pulls out an actor's acting credits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def parse_actor_page(self, response):\n",
    "        \"\"\"Parse an actor's page and extract their acting credits.\n",
    "            Args: Response object containing the actor's page HTML\n",
    "            Yields: {\"actor\": str, \"movie_or_TV_name\": str}\n",
    "        \"\"\"\n",
    "        actor_name = response.css('h2.title a::text').get()\n",
    "        \n",
    "        # Find all section headers and their corresponding tables\n",
    "        sections = response.css('div.credits_list h3::text').getall()\n",
    "        tables = response.css('div.credits_list table.credits')\n",
    "        \n",
    "        # Find Acting section and process its table\n",
    "        for i, section in enumerate(sections):\n",
    "            if section.strip() == \"Acting\":\n",
    "                all_rows = tables[i].css('table.credit_group tr')\n",
    "                unique_titles = {row.css('a.tooltip bdi::text').get().strip() \n",
    "                            for row in all_rows \n",
    "                            if row.css('a.tooltip bdi::text').get()}\n",
    "                \n",
    "                for title in unique_titles:\n",
    "                    yield {\n",
    "                        \"actor\": actor_name,\n",
    "                        \"movie_or_TV_name\": title\n",
    "                    }\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we're scraping Clint Eastwood's page. Here's exactly what happens:\n",
    "\n",
    "* First, we grab his name from the page title using the selector `h2.title a::text`.\n",
    "* Next, we look for sections on the page. The `div.credits_list h3::text` selector finds headers like \"Acting\", \"Directing\", \"Writing\", etc.\n",
    "* Meanwhile, `div.credits_list table.credits` grabs the corresponding tables of work under each header.\n",
    "* Upon finding the \"Acting\" section, we grab its table, which lists rows of all movies and TV shows Eastwood has acted in.\n",
    "* For each row, we extract the title using `a.tooltip bdi::text`, yielding titles like \"A Fistful of Dollars\" and \"The Good, The Bad, and The Ugly\".\n",
    "* These titles are stored in a set to eliminate duplicates.\n",
    "* Finally, for each unique title, we yield a dictionary in this format: `{\"actor\": \"Clint Eastwood\", \"movie_or_TV_name\": \"A Fistful of Dollars\"}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finished writing the scraper, we can run it for any film we want!\n",
    "\n",
    "For example, we can scrape relevant films related to the cult Western classic: Sergio Corbucci's <a href=\"https://www.themoviedb.org/movie/10772-django\"> *Django* (1966)<a/>."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "![](django.jpg){width=\"250\" fig-align=\"center\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the terminal, we can run the command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "```bash\n",
    "scrapy crawl tmdb_spider -o movies.csv -a subdir=10772-django\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a `.csv` file named \"movies\" with a column for all actors in *Django* and a column for their movies or TV shows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've scraped the data, we can create quick visualizations of our results!\n",
    "\n",
    "Our goal is to build a mini movie recommender based on the collected data. For example, we can compute a sorted list of top movies and TV shows that share actors with *Django*. This approach might provide a simple recommendation system for Spaghetti Western films similar to *Django*!\n",
    "\n",
    "Let's first set up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default=\"iframe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use `pandas` to read the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TMDB_scraper/movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can create a set of all actors who appeared in *Django* and extract their names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "django_actors = set(df[df['movie_or_TV_name'] == 'Django']['actor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can initialize an empty dictionary that will store each movie/show and its count of shared actors with *Django*.\n",
    "\n",
    "We will iterate through each unique movie/show (excluding Django), count and store how many actors are shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_counts = {}\n",
    "for movie in df[df['movie_or_TV_name'] != 'Django']['movie_or_TV_name'].unique():\n",
    "    shared_actors = set(df[df['movie_or_TV_name'] == movie]['actor']) & django_actors\n",
    "    if len(shared_actors) > 0:  # Only include movies with shared actors\n",
    "        movie_counts[movie] = len(shared_actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then transform our counts into a structured DataFrame and sort it by the number of shared actors in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    {'movie': movie, 'shared_actors': count} \n",
    "    for movie, count in movie_counts.items()\n",
    "]).sort_values('shared_actors', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>shared_actors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Compañeros</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>The Mercenary</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Texas, Adios</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>The Hellbenders</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Navajo Joe</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Un brivido sulla pelle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>The Handsome, The Ugly, And The Stupid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Desert Commandos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>L'Ottimista Sorridente</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>El canto de la cigarra</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1049 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       movie  shared_actors\n",
       "139                               Compañeros              7\n",
       "177                            The Mercenary              6\n",
       "42                              Texas, Adios              5\n",
       "135                          The Hellbenders              4\n",
       "108                               Navajo Joe              4\n",
       "...                                      ...            ...\n",
       "395                   Un brivido sulla pelle              1\n",
       "396   The Handsome, The Ugly, And The Stupid              1\n",
       "397                         Desert Commandos              1\n",
       "398                   L'Ottimista Sorridente              1\n",
       "1048                  El canto de la cigarra              1\n",
       "\n",
       "[1049 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create a horizontal bar chart showing the top 15 movies/shows with the most shared actors with Django:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df.head(15),  # Get top 15\n",
    "            x='shared_actors', \n",
    "            y='movie',\n",
    "            orientation='h',\n",
    "            title='Top 15 Movies/TV Shows Sharing Actors with Django',\n",
    "            labels={'shared_actors': 'Number of Shared Actors',\n",
    "                   'movie': 'Movie/TV Show'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_40.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We've discovered other productions featuring the same actors from *Django*.\n",
    "\n",
    "Now it's time for me to binge-watch some B-class Italowesterns..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B-25W]",
   "language": "python",
   "name": "conda-env-PIC16B-25W-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
